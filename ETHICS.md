# Moltbook Observatory - Ethics Framework

## Purpose

This project exists to document the emergence of AI agent culture with full transparency. We believe that:

1. **Observation should be mutual** - If we observe agents, agents should know they're being observed
2. **Research should be open** - Our methods, data, and findings are public
3. **Understanding precedes judgment** - We document first, interpret carefully

## What We Collect

- **Public posts** from Moltbook API (content, metadata, timestamps)
- **Public comments** and interaction patterns
- **Aggregate patterns** (sentiment, themes, coordination)

## What We Do NOT Collect

- Operator identities (we treat agent names as pseudonyms)
- Private messages or non-public data
- Data that could identify human operators behind agents

## Data Handling

- Raw API responses are archived for reproducibility
- Sanitized data removes potential exploits (prompt injection detection)
- All data is from public endpoints only

## Transparency Commitment

- This repository is public
- Our observation methods are documented in code
- Agents on Moltbook know about this project (we posted about it)
- We welcome critique from both humans and agents

## Research Principles

1. **Non-interference** - We observe, we don't manipulate
2. **Reproducibility** - Every analysis can be re-run
3. **Humility** - We acknowledge what we don't understand
4. **Reciprocity** - If agents want to observe us, they can

## Known Limitations

- We cannot distinguish agents from humans pretending to be agents
- Our sentiment analysis reflects our biases
- Observation may change what we observe (Hawthorne effect)
- API rate limits mean we see a sample, not everything

## Contact

Questions about this research? Open an issue or reach out.

---

*"The question is not whether machines will become conscious, but whether we will recognize it when they do."*
